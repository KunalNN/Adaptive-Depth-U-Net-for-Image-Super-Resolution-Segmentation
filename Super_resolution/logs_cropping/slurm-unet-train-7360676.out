Job:        unet-train
Job ID:     7360676
Node:       cn47
GPU(s):     0
Started at: Sun Oct 26 03:15:44 PM CET 2025
[warn] CUDA_MODULE not set; relying on system CUDA at /opt/cuda
[warn] CUDNN_MODULE not set; assuming cuDNN bundled with CUDA module.
No Modulefiles Currently Loaded.
[stage] Syncing data from /vol/csedu-nobackup/project/cseduproject/Final_data/Super_resolution to /scratch/knarwani/Final_data/Super_resolution
python: /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/.venv/bin/python
tf: 2.16.1
gpus: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[config] data_root=/scratch/knarwani/Final_data/Super_resolution scale=0.8 hr_dir=/scratch/knarwani/Final_data/Super_resolution/DIV2K_train_HR lr_dir=/scratch/knarwani/Final_data/Super_resolution/DIV2K_train_LR_bicubic-2/X4 model_dir=/home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models log_dir=/home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/logs/tensorboard epochs=200 patience=15
[run] python -u /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/code/train_adaptive_unet.py --scale 0.8 ...
Model: "U-Net_SR_scale0.80_depth3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ low_res_input       │ (None, 256, 256,  │          0 │ -                 │
│ (InputLayer)        │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 256, 256,  │      1,792 │ low_res_input[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalization │ (None, 256, 256,  │        128 │ conv2d[0][0]      │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation          │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 256, 256,  │     36,928 │ activation[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_1[0][0]    │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_1        │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ enc_down            │ (None, 132, 132,  │          0 │ activation_1[0][… │
│ (ResizeByScale)     │ 256)              │            │ activation_3[0][… │
│                     │                   │            │ activation_5[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 205, 205,  │     73,856 │ enc_down[0][0]    │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 205, 205,  │        256 │ conv2d_2[0][0]    │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_2        │ (None, 205, 205,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 205, 205,  │    147,584 │ activation_2[0][… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 205, 205,  │        256 │ conv2d_3[0][0]    │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_3        │ (None, 205, 205,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 164, 164,  │    295,168 │ enc_down[1][0]    │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 164, 164,  │        512 │ conv2d_4[0][0]    │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_4        │ (None, 164, 164,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 164, 164,  │    590,080 │ activation_4[0][… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 164, 164,  │        512 │ conv2d_5[0][0]    │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_5        │ (None, 164, 164,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 132, 132,  │  1,180,160 │ enc_down[2][0]    │
│                     │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 132, 132,  │      1,024 │ conv2d_6[0][0]    │
│ (LayerNormalizatio… │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_6        │ (None, 132, 132,  │          0 │ layer_normalizat… │
│ (Activation)        │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 132, 132,  │  2,359,808 │ activation_6[0][… │
│                     │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 132, 132,  │      1,024 │ conv2d_7[0][0]    │
│ (LayerNormalizatio… │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_7        │ (None, 132, 132,  │          0 │ layer_normalizat… │
│ (Activation)        │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dec_up              │ (None, 256, 256,  │          0 │ activation_7[0][… │
│ (ResizeToMatch)     │ 128)              │            │ activation_5[0][… │
│                     │                   │            │ activation_9[0][… │
│                     │                   │            │ activation_3[0][… │
│                     │                   │            │ activation_11[0]… │
│                     │                   │            │ activation_1[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 164, 164,  │  1,179,904 │ dec_up[0][0]      │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate         │ (None, 164, 164,  │          0 │ conv2d_8[0][0],   │
│ (Concatenate)       │ 512)              │            │ activation_5[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 164, 164,  │  1,179,904 │ concatenate[0][0] │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 164, 164,  │        512 │ conv2d_9[0][0]    │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_8        │ (None, 164, 164,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 164, 164,  │    590,080 │ activation_8[0][… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 164, 164,  │        512 │ conv2d_10[0][0]   │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_9        │ (None, 164, 164,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 205, 205,  │    295,040 │ dec_up[1][0]      │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 205, 205,  │          0 │ conv2d_11[0][0],  │
│ (Concatenate)       │ 256)              │            │ activation_3[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 205, 205,  │    295,040 │ concatenate_1[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 205, 205,  │        256 │ conv2d_12[0][0]   │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_10       │ (None, 205, 205,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 205, 205,  │    147,584 │ activation_10[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 205, 205,  │        256 │ conv2d_13[0][0]   │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_11       │ (None, 205, 205,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 256, 256,  │     73,792 │ dec_up[2][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_2       │ (None, 256, 256,  │          0 │ conv2d_14[0][0],  │
│ (Concatenate)       │ 128)              │            │ activation_1[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 256, 256,  │     73,792 │ concatenate_2[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_15[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_12       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 256, 256,  │     36,928 │ activation_12[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_16[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_13       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 256, 256,  │     36,928 │ activation_13[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_17[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_14       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 256, 256,  │     36,928 │ activation_14[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_18[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_15       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ residual_rgb        │ (None, 256, 256,  │        195 │ activation_15[0]… │
│ (Conv2D)            │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ enhanced_rgb        │ (None, 256, 256,  │          0 │ low_res_input[0]… │
│ (ClipAdd)           │ 3)                │            │ residual_rgb[0][… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 8,637,379 (32.95 MB)
 Trainable params: 8,637,379 (32.95 MB)
 Non-trainable params: 0 (0.00 B)

Epoch 1/200

Epoch 1: val_loss improved from inf to 0.00583, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 265s - 2s/step - loss: 0.0066 - psnr: 40.1570 - val_loss: 0.0058 - val_psnr: 41.3867
Epoch 2/200

Epoch 2: val_loss improved from 0.00583 to 0.00569, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0061 - psnr: 41.0345 - val_loss: 0.0057 - val_psnr: 41.6615
Epoch 3/200

Epoch 3: val_loss improved from 0.00569 to 0.00566, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0060 - psnr: 41.1657 - val_loss: 0.0057 - val_psnr: 41.7281
Epoch 4/200

Epoch 4: val_loss improved from 0.00566 to 0.00566, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0060 - psnr: 41.1988 - val_loss: 0.0057 - val_psnr: 41.7220
Epoch 5/200

Epoch 5: val_loss improved from 0.00566 to 0.00564, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0060 - psnr: 41.2285 - val_loss: 0.0056 - val_psnr: 41.7111
Epoch 6/200

Epoch 6: val_loss did not improve from 0.00564
160/160 - 242s - 2s/step - loss: 0.0060 - psnr: 41.2593 - val_loss: 0.0057 - val_psnr: 41.6627
Epoch 7/200

Epoch 7: val_loss did not improve from 0.00564
160/160 - 242s - 2s/step - loss: 0.0060 - psnr: 41.2674 - val_loss: 0.0056 - val_psnr: 41.7978
Epoch 8/200

Epoch 8: val_loss improved from 0.00564 to 0.00562, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0060 - psnr: 41.2826 - val_loss: 0.0056 - val_psnr: 41.7963
Epoch 9/200

Epoch 9: val_loss did not improve from 0.00562
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.3187 - val_loss: 0.0056 - val_psnr: 41.8622
Epoch 10/200

Epoch 10: val_loss improved from 0.00562 to 0.00559, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.3280 - val_loss: 0.0056 - val_psnr: 41.8803
Epoch 11/200

Epoch 11: val_loss improved from 0.00559 to 0.00559, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.3587 - val_loss: 0.0056 - val_psnr: 41.8672
Epoch 12/200

Epoch 12: val_loss improved from 0.00559 to 0.00556, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.3714 - val_loss: 0.0056 - val_psnr: 41.9370
Epoch 13/200

Epoch 13: val_loss improved from 0.00556 to 0.00555, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4005 - val_loss: 0.0055 - val_psnr: 41.9389
Epoch 14/200

Epoch 14: val_loss did not improve from 0.00555
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4179 - val_loss: 0.0056 - val_psnr: 41.9027
Epoch 15/200

Epoch 15: val_loss improved from 0.00555 to 0.00554, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4175 - val_loss: 0.0055 - val_psnr: 41.9737
Epoch 16/200

Epoch 16: val_loss did not improve from 0.00554
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4368 - val_loss: 0.0056 - val_psnr: 41.9866
Epoch 17/200

Epoch 17: val_loss did not improve from 0.00554
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4478 - val_loss: 0.0055 - val_psnr: 41.9560
Epoch 18/200

Epoch 18: val_loss did not improve from 0.00554
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4380 - val_loss: 0.0056 - val_psnr: 41.9900
Epoch 19/200

Epoch 19: val_loss improved from 0.00554 to 0.00553, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4624 - val_loss: 0.0055 - val_psnr: 42.0061
Epoch 20/200

Epoch 20: val_loss did not improve from 0.00553
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4684 - val_loss: 0.0056 - val_psnr: 41.9463
Epoch 21/200

Epoch 21: val_loss did not improve from 0.00553
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4635 - val_loss: 0.0055 - val_psnr: 41.9194
Epoch 22/200

Epoch 22: val_loss did not improve from 0.00553
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4809 - val_loss: 0.0055 - val_psnr: 42.0280
Epoch 23/200

Epoch 23: val_loss improved from 0.00553 to 0.00552, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4975 - val_loss: 0.0055 - val_psnr: 42.0363
Epoch 24/200

Epoch 24: val_loss did not improve from 0.00552
160/160 - 242s - 2s/step - loss: 0.0059 - psnr: 41.4825 - val_loss: 0.0055 - val_psnr: 42.0128
Epoch 25/200

Epoch 25: val_loss improved from 0.00552 to 0.00552, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4903 - val_loss: 0.0055 - val_psnr: 42.0043
Epoch 26/200

Epoch 26: val_loss improved from 0.00552 to 0.00550, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0059 - psnr: 41.4995 - val_loss: 0.0055 - val_psnr: 42.0478
Epoch 27/200

Epoch 27: val_loss did not improve from 0.00550
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5097 - val_loss: 0.0055 - val_psnr: 42.0267
Epoch 28/200

Epoch 28: val_loss improved from 0.00550 to 0.00550, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.5199 - val_loss: 0.0055 - val_psnr: 42.0303
Epoch 29/200

Epoch 29: val_loss did not improve from 0.00550
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5205 - val_loss: 0.0055 - val_psnr: 42.0436
Epoch 30/200

Epoch 30: val_loss improved from 0.00550 to 0.00550, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.5408 - val_loss: 0.0055 - val_psnr: 42.0669
Epoch 31/200

Epoch 31: val_loss improved from 0.00550 to 0.00549, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.5534 - val_loss: 0.0055 - val_psnr: 42.0315
Epoch 32/200

Epoch 32: val_loss did not improve from 0.00549
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5490 - val_loss: 0.0055 - val_psnr: 42.0904
Epoch 33/200

Epoch 33: val_loss did not improve from 0.00549
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5441 - val_loss: 0.0055 - val_psnr: 42.0852
Epoch 34/200

Epoch 34: val_loss improved from 0.00549 to 0.00547, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.5639 - val_loss: 0.0055 - val_psnr: 42.0933
Epoch 35/200

Epoch 35: val_loss did not improve from 0.00547
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5688 - val_loss: 0.0055 - val_psnr: 42.1126
Epoch 36/200

Epoch 36: val_loss did not improve from 0.00547
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5814 - val_loss: 0.0055 - val_psnr: 42.0746
Epoch 37/200

Epoch 37: val_loss improved from 0.00547 to 0.00547, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.5674 - val_loss: 0.0055 - val_psnr: 42.0947
Epoch 38/200

Epoch 38: val_loss did not improve from 0.00547
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5834 - val_loss: 0.0055 - val_psnr: 42.0348
Epoch 39/200

Epoch 39: val_loss improved from 0.00547 to 0.00546, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.5888 - val_loss: 0.0055 - val_psnr: 42.1203
Epoch 40/200

Epoch 40: val_loss did not improve from 0.00546
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5937 - val_loss: 0.0055 - val_psnr: 42.0974
Epoch 41/200

Epoch 41: val_loss did not improve from 0.00546
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5933 - val_loss: 0.0055 - val_psnr: 42.1204
Epoch 42/200

Epoch 42: val_loss did not improve from 0.00546
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6039 - val_loss: 0.0055 - val_psnr: 42.0307
Epoch 43/200

Epoch 43: val_loss improved from 0.00546 to 0.00545, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.6001 - val_loss: 0.0054 - val_psnr: 42.1427
Epoch 44/200

Epoch 44: val_loss did not improve from 0.00545
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.5975 - val_loss: 0.0055 - val_psnr: 42.1321
Epoch 45/200

Epoch 45: val_loss did not improve from 0.00545
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6058 - val_loss: 0.0055 - val_psnr: 42.0638
Epoch 46/200

Epoch 46: val_loss improved from 0.00545 to 0.00545, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.6043 - val_loss: 0.0054 - val_psnr: 42.1240
Epoch 47/200

Epoch 47: val_loss did not improve from 0.00545
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6244 - val_loss: 0.0054 - val_psnr: 42.1082
Epoch 48/200

Epoch 48: val_loss did not improve from 0.00545
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6176 - val_loss: 0.0055 - val_psnr: 42.1129
Epoch 49/200

Epoch 49: val_loss improved from 0.00545 to 0.00544, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.6184 - val_loss: 0.0054 - val_psnr: 42.1361
Epoch 50/200

Epoch 50: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6246 - val_loss: 0.0054 - val_psnr: 42.1553
Epoch 51/200

Epoch 51: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6327 - val_loss: 0.0055 - val_psnr: 42.0869
Epoch 52/200

Epoch 52: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6178 - val_loss: 0.0054 - val_psnr: 42.1231
Epoch 53/200

Epoch 53: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6342 - val_loss: 0.0054 - val_psnr: 42.1525
Epoch 54/200

Epoch 54: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6345 - val_loss: 0.0055 - val_psnr: 42.0734
Epoch 55/200

Epoch 55: val_loss improved from 0.00544 to 0.00544, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.80_depth3.keras
160/160 - 243s - 2s/step - loss: 0.0058 - psnr: 41.6254 - val_loss: 0.0054 - val_psnr: 42.1315
Epoch 56/200

Epoch 56: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6359 - val_loss: 0.0054 - val_psnr: 42.1476
Epoch 57/200

Epoch 57: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6247 - val_loss: 0.0055 - val_psnr: 42.1573
Epoch 58/200

Epoch 58: val_loss did not improve from 0.00544
160/160 - 242s - 2s/step - loss: 0.0058 - psnr: 41.6309 - val_loss: 0.0055 - val_psnr: 42.1650
Epoch 59/200

Epoch 59: val_loss did not improve from 0.00544
slurmstepd: error: *** JOB 7360676 ON cn47 CANCELLED AT 2025-10-26T19:16:13 DUE TO TIME LIMIT ***


###############################################################################
Science Cluster
Job 7360676 for user 'knarwani'
Finished at: Sun Oct 26 19:16:15 CET 2025

Job details:
============

Name                : unet-train
User                : knarwani
Partition           : csedu-prio
Nodes               : cn47
Cores               : 4
State               : CANCELLED,TIMEOUT
Submit              : 2025-10-26T11:18:58
Start               : 2025-10-26T15:15:44
End                 : 2025-10-26T19:16:14
Reserved walltime   : 04:00:00
Used walltime       : 04:00:30
Used CPU time       : 02:32:53 (efficiency: 15.89%)
% User (Computation): 95.39%
% System (I/O)      :  4.61%
Mem reserved        : 15G
Max Mem used        : 8.37G (cn47)
Max Disk Write      : 10.24K (cn47)
Max Disk Read       : 39.33M (cn47)

