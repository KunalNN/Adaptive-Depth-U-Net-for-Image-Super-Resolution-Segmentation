Job:        unet-train
Job ID:     7361800
Node:       cn47
GPU(s):     0
Started at: Mon Oct 27 01:38:54 PM CET 2025
[warn] CUDA_MODULE not set; relying on system CUDA at /opt/cuda
[warn] CUDNN_MODULE not set; assuming cuDNN bundled with CUDA module.
No Modulefiles Currently Loaded.
[stage] Syncing data from /vol/csedu-nobackup/project/cseduproject/Final_data/Super_resolution to /scratch/knarwani/Final_data/Super_resolution
python: /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/.venv/bin/python
tf: 2.16.1
gpus: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
[config] data_root=/scratch/knarwani/Final_data/Super_resolution scale=0.9 hr_dir=/scratch/knarwani/Final_data/Super_resolution/DIV2K_train_HR lr_dir=/scratch/knarwani/Final_data/Super_resolution/DIV2K_train_LR_bicubic-2/X4 model_dir=/home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models log_dir=/home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/logs/tensorboard epochs=200 patience=15
[run] python -u /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/code/train_adaptive_unet.py --scale 0.9 ...
Model: "U-Net_SR_scale0.90_depth3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ low_res_input       │ (None, 256, 256,  │          0 │ -                 │
│ (InputLayer)        │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 256, 256,  │      1,792 │ low_res_input[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalization │ (None, 256, 256,  │        128 │ conv2d[0][0]      │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation          │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 256, 256,  │     36,928 │ activation[0][0]  │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_1[0][0]    │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_1        │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ enc_down            │ (None, 188, 188,  │          0 │ activation_1[0][… │
│ (ResizeByScale)     │ 256)              │            │ activation_3[0][… │
│                     │                   │            │ activation_5[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 231, 231,  │     73,856 │ enc_down[0][0]    │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 231, 231,  │        256 │ conv2d_2[0][0]    │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_2        │ (None, 231, 231,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 231, 231,  │    147,584 │ activation_2[0][… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 231, 231,  │        256 │ conv2d_3[0][0]    │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_3        │ (None, 231, 231,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 208, 208,  │    295,168 │ enc_down[1][0]    │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 208, 208,  │        512 │ conv2d_4[0][0]    │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_4        │ (None, 208, 208,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 208, 208,  │    590,080 │ activation_4[0][… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 208, 208,  │        512 │ conv2d_5[0][0]    │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_5        │ (None, 208, 208,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 188, 188,  │  1,180,160 │ enc_down[2][0]    │
│                     │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 188, 188,  │      1,024 │ conv2d_6[0][0]    │
│ (LayerNormalizatio… │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_6        │ (None, 188, 188,  │          0 │ layer_normalizat… │
│ (Activation)        │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 188, 188,  │  2,359,808 │ activation_6[0][… │
│                     │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 188, 188,  │      1,024 │ conv2d_7[0][0]    │
│ (LayerNormalizatio… │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_7        │ (None, 188, 188,  │          0 │ layer_normalizat… │
│ (Activation)        │ 512)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dec_up              │ (None, 256, 256,  │          0 │ activation_7[0][… │
│ (ResizeToMatch)     │ 128)              │            │ activation_5[0][… │
│                     │                   │            │ activation_9[0][… │
│                     │                   │            │ activation_3[0][… │
│                     │                   │            │ activation_11[0]… │
│                     │                   │            │ activation_1[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 208, 208,  │  1,179,904 │ dec_up[0][0]      │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate         │ (None, 208, 208,  │          0 │ conv2d_8[0][0],   │
│ (Concatenate)       │ 512)              │            │ activation_5[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 208, 208,  │  1,179,904 │ concatenate[0][0] │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 208, 208,  │        512 │ conv2d_9[0][0]    │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_8        │ (None, 208, 208,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 208, 208,  │    590,080 │ activation_8[0][… │
│                     │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 208, 208,  │        512 │ conv2d_10[0][0]   │
│ (LayerNormalizatio… │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_9        │ (None, 208, 208,  │          0 │ layer_normalizat… │
│ (Activation)        │ 256)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 231, 231,  │    295,040 │ dec_up[1][0]      │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 231, 231,  │          0 │ conv2d_11[0][0],  │
│ (Concatenate)       │ 256)              │            │ activation_3[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 231, 231,  │    295,040 │ concatenate_1[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 231, 231,  │        256 │ conv2d_12[0][0]   │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_10       │ (None, 231, 231,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 231, 231,  │    147,584 │ activation_10[0]… │
│                     │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 231, 231,  │        256 │ conv2d_13[0][0]   │
│ (LayerNormalizatio… │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_11       │ (None, 231, 231,  │          0 │ layer_normalizat… │
│ (Activation)        │ 128)              │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 256, 256,  │     73,792 │ dec_up[2][0]      │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_2       │ (None, 256, 256,  │          0 │ conv2d_14[0][0],  │
│ (Concatenate)       │ 128)              │            │ activation_1[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 256, 256,  │     73,792 │ concatenate_2[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_15[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_12       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 256, 256,  │     36,928 │ activation_12[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_16[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_13       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 256, 256,  │     36,928 │ activation_13[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_17[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_14       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 256, 256,  │     36,928 │ activation_14[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ layer_normalizatio… │ (None, 256, 256,  │        128 │ conv2d_18[0][0]   │
│ (LayerNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_15       │ (None, 256, 256,  │          0 │ layer_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ residual_rgb        │ (None, 256, 256,  │        195 │ activation_15[0]… │
│ (Conv2D)            │ 3)                │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ enhanced_rgb        │ (None, 256, 256,  │          0 │ low_res_input[0]… │
│ (ClipAdd)           │ 3)                │            │ residual_rgb[0][… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 8,637,379 (32.95 MB)
 Trainable params: 8,637,379 (32.95 MB)
 Non-trainable params: 0 (0.00 B)

Epoch 1/200

Epoch 1: val_loss improved from inf to 0.00568, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 405s - 634ms/step - loss: 0.0063 - psnr: 40.7646 - val_loss: 0.0057 - val_psnr: 41.6797
Epoch 2/200

Epoch 2: val_loss improved from 0.00568 to 0.00564, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0060 - psnr: 41.1619 - val_loss: 0.0056 - val_psnr: 41.7184
Epoch 3/200

Epoch 3: val_loss improved from 0.00564 to 0.00562, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 602ms/step - loss: 0.0060 - psnr: 41.2251 - val_loss: 0.0056 - val_psnr: 41.7983
Epoch 4/200

Epoch 4: val_loss did not improve from 0.00562
640/640 - 384s - 600ms/step - loss: 0.0060 - psnr: 41.2531 - val_loss: 0.0056 - val_psnr: 41.8486
Epoch 5/200

Epoch 5: val_loss did not improve from 0.00562
640/640 - 384s - 600ms/step - loss: 0.0060 - psnr: 41.2975 - val_loss: 0.0057 - val_psnr: 41.4591
Epoch 6/200

Epoch 6: val_loss improved from 0.00562 to 0.00560, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0059 - psnr: 41.3329 - val_loss: 0.0056 - val_psnr: 41.9288
Epoch 7/200

Epoch 7: val_loss improved from 0.00560 to 0.00556, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 384s - 600ms/step - loss: 0.0059 - psnr: 41.4003 - val_loss: 0.0056 - val_psnr: 41.9687
Epoch 8/200

Epoch 8: val_loss improved from 0.00556 to 0.00555, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0059 - psnr: 41.4117 - val_loss: 0.0056 - val_psnr: 41.9459
Epoch 9/200

Epoch 9: val_loss improved from 0.00555 to 0.00552, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0059 - psnr: 41.4680 - val_loss: 0.0055 - val_psnr: 42.0304
Epoch 10/200

Epoch 10: val_loss improved from 0.00552 to 0.00552, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0059 - psnr: 41.4865 - val_loss: 0.0055 - val_psnr: 41.9747
Epoch 11/200

Epoch 11: val_loss did not improve from 0.00552
640/640 - 384s - 600ms/step - loss: 0.0059 - psnr: 41.4894 - val_loss: 0.0055 - val_psnr: 41.8950
Epoch 12/200

Epoch 12: val_loss did not improve from 0.00552
640/640 - 384s - 601ms/step - loss: 0.0058 - psnr: 41.5058 - val_loss: 0.0056 - val_psnr: 42.0194
Epoch 13/200

Epoch 13: val_loss improved from 0.00552 to 0.00550, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0058 - psnr: 41.5017 - val_loss: 0.0055 - val_psnr: 42.0711
Epoch 14/200

Epoch 14: val_loss did not improve from 0.00550
640/640 - 384s - 600ms/step - loss: 0.0058 - psnr: 41.5252 - val_loss: 0.0055 - val_psnr: 41.9177
Epoch 15/200

Epoch 15: val_loss did not improve from 0.00550
640/640 - 384s - 600ms/step - loss: 0.0058 - psnr: 41.5242 - val_loss: 0.0055 - val_psnr: 42.0635
Epoch 16/200

Epoch 16: val_loss improved from 0.00550 to 0.00547, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0058 - psnr: 41.5396 - val_loss: 0.0055 - val_psnr: 42.1111
Epoch 17/200

Epoch 17: val_loss improved from 0.00547 to 0.00547, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0058 - psnr: 41.5430 - val_loss: 0.0055 - val_psnr: 42.1075
Epoch 18/200

Epoch 18: val_loss did not improve from 0.00547
640/640 - 384s - 600ms/step - loss: 0.0058 - psnr: 41.5761 - val_loss: 0.0055 - val_psnr: 42.0971
Epoch 19/200

Epoch 19: val_loss improved from 0.00547 to 0.00546, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 601ms/step - loss: 0.0058 - psnr: 41.5767 - val_loss: 0.0055 - val_psnr: 42.0998
Epoch 20/200

Epoch 20: val_loss did not improve from 0.00546
640/640 - 384s - 600ms/step - loss: 0.0058 - psnr: 41.5772 - val_loss: 0.0055 - val_psnr: 42.0390
Epoch 21/200

Epoch 21: val_loss did not improve from 0.00546
640/640 - 384s - 600ms/step - loss: 0.0058 - psnr: 41.5859 - val_loss: 0.0055 - val_psnr: 41.9798
Epoch 22/200

Epoch 22: val_loss improved from 0.00546 to 0.00545, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 385s - 602ms/step - loss: 0.0058 - psnr: 41.5805 - val_loss: 0.0055 - val_psnr: 42.1412
Epoch 23/200

Epoch 23: val_loss improved from 0.00545 to 0.00544, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 383s - 599ms/step - loss: 0.0058 - psnr: 41.5989 - val_loss: 0.0054 - val_psnr: 42.1518
Epoch 24/200

Epoch 24: val_loss did not improve from 0.00544
640/640 - 383s - 598ms/step - loss: 0.0058 - psnr: 41.6009 - val_loss: 0.0055 - val_psnr: 42.1120
Epoch 25/200

Epoch 25: val_loss improved from 0.00544 to 0.00544, saving model to /home/knarwani/thesis/git/Adaptive-Depth-U-Net-for-Image-Super-Resolution-Segmentation/Super_resolution/models/unet_adaptive_scale_new_loss0.90_depth3.keras
640/640 - 383s - 599ms/step - loss: 0.0058 - psnr: 41.6001 - val_loss: 0.0054 - val_psnr: 42.1486
Epoch 26/200

Epoch 26: val_loss did not improve from 0.00544
640/640 - 383s - 598ms/step - loss: 0.0058 - psnr: 41.6123 - val_loss: 0.0055 - val_psnr: 42.1325
Epoch 27/200

Epoch 27: val_loss did not improve from 0.00544
640/640 - 383s - 598ms/step - loss: 0.0058 - psnr: 41.6137 - val_loss: 0.0054 - val_psnr: 42.1302
Epoch 28/200
slurmstepd: error: *** JOB 7361800 ON cn47 CANCELLED AT 2025-10-27T16:36:59 ***


###############################################################################
Science Cluster
Job 7361800 for user 'knarwani'
Finished at: Mon Oct 27 16:37:01 CET 2025

Job details:
============

Name                : unet-train
User                : knarwani
Partition           : csedu-prio
Nodes               : cn47
Cores               : 4
State               : CANCELLED,CANCELLED by 41441
Submit              : 2025-10-27T13:38:54
Start               : 2025-10-27T13:38:54
End                 : 2025-10-27T16:37:00
Reserved walltime   : 04:00:00
Used walltime       : 02:58:06
Used CPU time       : 02:01:41 (efficiency: 17.08%)
% User (Computation): 95.96%
% System (I/O)      :  4.05%
Mem reserved        : 15G
Max Mem used        : 8.36G (cn47)
Max Disk Write      : 10.24K (cn47)
Max Disk Read       : 39.33M (cn47)

